# vision_based_transfomer_architectures

The project plans to analyze various transformer models using vision-based approaches
with two distinct methodologies. The first methodology is training from scratch, the
second method is fine-tuning the models with the chosen dataset.
Chosen dataset is Butterfly & Months Image Classification 100 species from Kaggle.[1] 

The dataset contains 12594 trains, 500 tests, and 500 validation images. Each imageâ€™s size is 224 x 224.
There are 100 different classes in the dataset.
Determined models to analyze:
1. ViT(Vision-based Transformer)
2. Swin Transformers
3. Data-efficient Image Transformers(DeIT)

   
3 different methods are applied to implement models:
- From the Scratch
- Fine-tuning
- Feature Extraction 

### Results:
![vit](https://github.com/asumandemireriden/vision_based_transfomer_architectures/assets/73910961/85d73db2-2749-4771-accf-e9dee8b82dd5)

 ##### Figure 1:   Result of 3 different methods with ViT 


![swin](https://github.com/asumandemireriden/vision_based_transfomer_architectures/assets/73910961/56cb2c17-f346-4ca0-9996-193724627d73)

##### Figure 2: Result of 3 different methods with Swin Transformer

![deit](https://github.com/asumandemireriden/vision_based_transfomer_architectures/assets/73910961/00d03c69-4405-4ff8-b62c-e6498cf057bc)

##### Figure 3: Result of 2 different methods with Transformer




References


[1] Butterfly Image Classification 100 species, [Online].

Available:
https://www.kaggle.com/datasets/gpiosenka/butterfly-images40-species
